
# Everybody Machine Learning Dance Now!

## Project Abstract
Bringing together the disciplines of computer science and dance, our project is focused on dance sequence generation for the human body based off any provided song from the Spotify streaming platform. It utilizes machine learning via neural networks, hours of dance footage, and the spotify API to bring in music data. We aim to inspire new and exciting choreography and at the same time produce a visualization that is in and of itself a piece of art.

## Environment Setup

### Recording Dance via Kinect

All files necessary for recording dance can be found in the **data collection** folder of this repository.
1.  Kinect Sensor v2 hardware (including USB 2.0 connection cord)
2.  [TouchDesigner](https://derivative.ca/download): Additional [information](https://derivative.ca/UserGuide/Kinect) about Kinect 2 Support in TouchDesigner.
3. [Pure Data](https://puredata.info/): The necessary files to open while recording dance are as follows: pdtestDr.Snow.pd, routeskeleton.pd, and toFile.pd. Note that in all of these files, the Pure Data toggles will need to be activated to allow data through the pipeline. 

### Training Data

<ol>
  <li> <a href="https://jupyter.org/install" >Jupyter Notebooks</a> 
    <ul>
      <li> Follow the above link for instructions on how to setup Notebooks </li>
      <li> Run an instance on your machine to run the project files cell-by-cell </li>
    </ul>
  </li>
  <li> pandas </li>
  <li> matplotlib </li>
  <li> sklearn </li>
  <li> Spotipy </li>
</ol>

### Producing Animations

<ol>
  <li> Processing </li>
</ol>

## Other Materials
[Poster](https://drive.google.com/file/d/1I_vOGQIQij2UzXmbQAJTZQCqG5-yDhEb/view?usp=sharing)

[Drive Folder with Milestones and Progress Presentations](https://drive.google.com/drive/folders/1WIof7IkIQthz4JQYmHtaGFFs6BY_jjKF?usp=sharing) 
